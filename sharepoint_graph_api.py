"""
SharePoint QA Data Processing using Microsoft Graph API
S·ª≠ d·ª•ng API credentials t·ª´ IT team ƒë·ªÉ truy c·∫≠p SharePoint
"""

import pandas as pd
import requests
import os
import sys
import io
from datetime import datetime
import msal
from config import GRAPH_API_CONFIG, SHAREPOINT_CONFIG, FILE_PATHS, OUTPUT_CONFIG, QA_CONFIG

class SharePointGraphAPI:
    def __init__(self):
        self.access_token = None
        self.base_url = "https://graph.microsoft.com/v1.0"
        self.authenticate()
    
    def authenticate(self):
        """Authenticate s·ª≠ d·ª•ng Client ID v√† Client Secret t·ª´ IT team"""
        try:
            print("üîê Authenticating with Microsoft Graph API...")
            
            # T·∫°o MSAL confidential client application
            app = msal.ConfidentialClientApplication(
                GRAPH_API_CONFIG['client_id'],
                authority=GRAPH_API_CONFIG['authority'],
                client_credential=GRAPH_API_CONFIG['client_secret']
            )
            
            # Acquire token cho application
            result = app.acquire_token_silent(GRAPH_API_CONFIG['scopes'], account=None)
            
            if not result:
                print("üì° Getting new access token...")
                result = app.acquire_token_for_client(scopes=GRAPH_API_CONFIG['scopes'])
            
            if "access_token" in result:
                self.access_token = result['access_token']
                print("‚úÖ Successfully authenticated with Microsoft Graph API")
                return True
            else:
                print(f"‚ùå Authentication failed: {result.get('error_description', 'Unknown error')}")
                return False
                
        except Exception as e:
            print(f"‚ùå Authentication error: {str(e)}")
            return False
    
    def get_headers(self):
        """Get headers cho API requests"""
        return {
            'Authorization': f'Bearer {self.access_token}',
            'Content-Type': 'application/json'
        }
    
    def get_site_id(self):
        """Get SharePoint site ID"""
        try:
            url = f"{self.base_url}/sites/masangroup.sharepoint.com:/sites/MCH.MMB.QA"
            response = requests.get(url, headers=self.get_headers())
            
            if response.status_code == 200:
                site_data = response.json()
                site_id = site_data['id']
                print(f"‚úÖ Found site ID: {site_id}")
                return site_id
            else:
                print(f"‚ùå Error getting site ID: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error getting site ID: {str(e)}")
            return None
    
    def list_drives(self, site_id):
        """List all drives in the site"""
        try:
            url = f"{self.base_url}/sites/{site_id}/drives"
            response = requests.get(url, headers=self.get_headers())
            
            if response.status_code == 200:
                drives = response.json()['value']
                print(f"üìÅ Found {len(drives)} drives:")
                for drive in drives:
                    print(f"  - {drive['name']} (ID: {drive['id']})")
                return drives
            else:
                print(f"‚ùå Error listing drives: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"‚ùå Error listing drives: {str(e)}")
            return []
    
    def find_file_in_drive(self, site_id, folder_path, filename):
        """T√¨m file trong SharePoint drive"""
        try:
            # Get drives
            drives = self.list_drives(site_id)
            
            for drive in drives:
                drive_id = drive['id']
                
                # Search for file trong drive n√†y
                search_url = f"{self.base_url}/sites/{site_id}/drives/{drive_id}/root/search(q='{filename}')"
                response = requests.get(search_url, headers=self.get_headers())
                
                if response.status_code == 200:
                    items = response.json().get('value', [])
                    
                    for item in items:
                        if item['name'] == filename:
                            print(f"‚úÖ Found file: {filename} in drive: {drive['name']}")
                            return drive_id, item['id'], item['@microsoft.graph.downloadUrl']
            
            print(f"‚ùå File not found: {filename}")
            return None, None, None
            
        except Exception as e:
            print(f"‚ùå Error finding file {filename}: {str(e)}")
            return None, None, None
    
    def download_excel_file(self, download_url, description=""):
        """Download Excel file t·ª´ SharePoint"""
        try:
            print(f"üì• Downloading {description}...")
            
            response = requests.get(download_url)
            
            if response.status_code == 200:
                # Read Excel t·ª´ memory
                excel_data = io.BytesIO(response.content)
                df = pd.read_excel(excel_data)
                
                print(f"‚úÖ Successfully downloaded {description}: {len(df)} rows")
                return df
            else:
                print(f"‚ùå Error downloading {description}: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error downloading {description}: {str(e)}")
            return None
    
    def process_qa_file(self, file_config):
        """Process m·ªôt file QA c·ª• th·ªÉ"""
        try:
            # Get site ID
            site_id = self.get_site_id()
            if not site_id:
                return None
            
            # Find v√† download file
            drive_id, file_id, download_url = self.find_file_in_drive(
                site_id, 
                file_config['folder'], 
                file_config['filename']
            )
            
            if download_url:
                df = self.download_excel_file(download_url, file_config['description'])
                return df
            else:
                print(f"‚ùå Could not find file: {file_config['filename']}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error processing file {file_config['filename']}: {str(e)}")
            return None

class QADataProcessor:
    """Class ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu QA sau khi download t·ª´ SharePoint"""
    
    def __init__(self):
        self.sharepoint = SharePointGraphAPI()
        self.processed_data = {}
    
    def download_all_files(self):
        """Download t·∫•t c·∫£ files QA t·ª´ SharePoint"""
        print("\nüöÄ Starting QA data download process...")
        
        for file_key, file_config in FILE_PATHS.items():
            print(f"\n--- Processing {file_config['description']} ---")
            df = self.sharepoint.process_qa_file(file_config)
            
            if df is not None:
                self.processed_data[file_key] = df
                print(f"‚úÖ Successfully processed {file_config['description']}")
            else:
                print(f"‚ùå Failed to process {file_config['description']}")
        
        return len(self.processed_data) > 0
    
    def analyze_quality_data(self):
        """Ph√¢n t√≠ch d·ªØ li·ªáu quality - implement your existing logic here"""
        try:
            print("\nüìä Analyzing quality data...")
            
            # Implement your existing data processing logic here
            # V√≠ d·ª•: extract production info, standardize dates, etc.
            
            if 'sample_id' in self.processed_data:
                sample_df = self.processed_data['sample_id']
                print(f"üìã Sample ID data: {len(sample_df)} records")
                
                # Add your existing processing logic
                # - Clean dates
                # - Extract production information  
                # - Match QA and leaders
                # - Calculate quality metrics
            
            if 'quality_daily' in self.processed_data:
                daily_df = self.processed_data['quality_daily']
                print(f"üìà Daily quality data: {len(daily_df)} records")
                
                # Add your existing daily quality processing
            
            print("‚úÖ Quality data analysis completed")
            return True
            
        except Exception as e:
            print(f"‚ùå Error in quality analysis: {str(e)}")
            return False
    
    def generate_reports(self):
        """Generate b√°o c√°o QA"""
        try:
            print("\nüìù Generating QA reports...")
            
            # Create output directory
            os.makedirs(OUTPUT_CONFIG['local_output_dir'], exist_ok=True)
            
            # Generate timestamp
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # Main processed data file
            main_output = os.path.join(
                OUTPUT_CONFIG['local_output_dir'],
                OUTPUT_CONFIG['processed_filename'].format(timestamp=timestamp)
            )
            
            with pd.ExcelWriter(main_output, engine='openpyxl') as writer:
                for file_key, df in self.processed_data.items():
                    sheet_name = FILE_PATHS[file_key]['description'].replace(' ', '_')[:30]
                    df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            print(f"‚úÖ Main report saved: {main_output}")
            
            # Summary report
            summary_output = os.path.join(
                OUTPUT_CONFIG['local_output_dir'],
                OUTPUT_CONFIG['summary_filename'].format(timestamp=timestamp)
            )
            
            # Create summary DataFrame
            summary_data = []
            for file_key, df in self.processed_data.items():
                summary_data.append({
                    'File': FILE_PATHS[file_key]['description'],
                    'Records': len(df),
                    'Columns': len(df.columns),
                    'Last_Updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                })
            
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(summary_output, index=False)
            
            print(f"‚úÖ Summary report saved: {summary_output}")
            return True
            
        except Exception as e:
            print(f"‚ùå Error generating reports: {str(e)}")
            return False

def main():
    """Main function"""
    print("="*60)
    print("üè≠ MASAN QA DATA PROCESSING - SHAREPOINT INTEGRATION")
    print("="*60)
    
    # Ki·ªÉm tra credentials
    if not GRAPH_API_CONFIG['client_secret']:
        print("‚ùå CLIENT_SECRET not found. Please ask IT team for this credential.")
        print("Set it as GitHub secret: CLIENT_SECRET")
        sys.exit(1)
    
    # Initialize processor
    processor = QADataProcessor()
    
    # Check authentication
    if not processor.sharepoint.access_token:
        print("‚ùå Failed to authenticate with SharePoint")
        sys.exit(1)
    
    # Download all files
    if not processor.download_all_files():
        print("‚ùå Failed to download QA files")
        sys.exit(1)
    
    # Analyze data
    if not processor.analyze_quality_data():
        print("‚ùå Failed to analyze quality data")
        sys.exit(1)
    
    # Generate reports
    if not processor.generate_reports():
        print("‚ùå Failed to generate reports")
        sys.exit(1)
    
    print("\nüéâ QA Data processing completed successfully!")
    print(f"üìÅ Check output folder: {OUTPUT_CONFIG['local_output_dir']}")

if __name__ == "__main__":
    main()
