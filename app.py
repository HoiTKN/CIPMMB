import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import time
import gspread
import os
import json
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from plotly.subplots import make_subplots

# Set page configuration with improved styling
st.set_page_config(
    page_title="B√°o c√°o ch·∫•t l∆∞·ª£ng CF MMB",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS to improve the look and feel
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.8rem;
        font-weight: 600;
        color: #1E3A8A;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
    }
    .metric-card {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .metric-title {
        font-size: 1.2rem;
        font-weight: 600;
        color: #64748b;
    }
    .metric-value {
        font-size: 2.5rem;
        font-weight: 700;
        color: #1E3A8A;
    }
    .stDataFrame {
        border-radius: 10px !important;
        overflow: hidden;
    }
    .stDataFrame table {
        border-collapse: collapse;
        width: 100%;
    }
    .stDataFrame th {
        background-color: #1E3A8A !important;
        color: white !important;
        font-weight: 600;
        padding: 12px !important;
    }
    .stDataFrame td {
        padding: 10px !important;
    }
    .stDataFrame tr:nth-child(even) {
        background-color: #f8f9fa;
    }
    .sidebar .sidebar-content {
        background-color: #f8f9fa;
    }
    [data-testid="stSidebar"] {
        background-color: #f8f9fa;
    }
    .insight-card {
        background-color: #f0f7ff;
        border-left: 5px solid #3b82f6;
        border-radius: 5px;
        padding: 15px;
        margin-bottom: 15px;
    }
    .insight-title {
        font-size: 1.1rem;
        font-weight: 600;
        color: #1e40af;
        margin-bottom: 8px;
    }
    .insight-content {
        color: #334155;
        font-size: 0.95rem;
    }
    .warning-card {
        background-color: #fff1f2;
        border-left: 5px solid #e11d48;
        border-radius: 5px;
        padding: 15px;
        margin-bottom: 15px;
    }
    .warning-title {
        font-size: 1.1rem;
        font-weight: 600;
        color: #be123c;
        margin-bottom: 8px;
    }
    .tab-container {
        margin-top: 1rem;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: white;
        border-radius: 4px 4px 0px 0px;
        gap: 1px;
        padding-top: 10px;
        padding-bottom: 10px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #1E3A8A;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

# Define the scopes
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive"
]

# Authentication function
def authenticate():
    """Authentication using OAuth token"""
    try:
        creds = None
        
        # Check if token.json exists first
        if os.path.exists('token.json'):
            try:
                creds = Credentials.from_authorized_user_file('token.json', SCOPES)
            except Exception as e:
                st.error(f"L·ªói khi t·∫£i token.json: {e}")
        # Otherwise create it from the environment variable or Streamlit secrets
        elif 'GOOGLE_TOKEN_JSON' in os.environ:
            try:
                token_info = os.environ.get('GOOGLE_TOKEN_JSON')
                with open('token.json', 'w') as f:
                    f.write(token_info)
                creds = Credentials.from_authorized_user_file('token.json', SCOPES)
            except Exception as e:
                st.error(f"L·ªói khi t·∫£i t·ª´ bi·∫øn m√¥i tr∆∞·ªùng: {e}")
        elif 'GOOGLE_TOKEN_JSON' in st.secrets:
            try:
                token_info = st.secrets['GOOGLE_TOKEN_JSON']
                with open('token.json', 'w') as f:
                    f.write(token_info)
                creds = Credentials.from_authorized_user_file('token.json', SCOPES)
            except Exception as e:
                st.error(f"L·ªói khi t·∫£i t·ª´ Streamlit secrets: {e}")
        else:
            st.error("‚ùå Kh√¥ng t√¨m th·∫•y file token.json ho·∫∑c GOOGLE_TOKEN_JSON")
            return None
        
        # Refresh token if expired
        if creds and creds.expired and creds.refresh_token:
            try:
                creds.refresh(Request())
                with open('token.json', 'w') as token:
                    token.write(creds.to_json())
            except Exception as e:
                st.error(f"L·ªói khi l√†m m·ªõi token: {e}")
                
        # Return authorized client
        if creds:
            return gspread.authorize(creds)
        else:
            return None
    
    except Exception as e:
        st.error(f"‚ùå L·ªói x√°c th·ª±c: {str(e)}")
        return None

# Function to load complaint data
@st.cache_data(ttl=300)  # Cache for 5 minutes
def load_complaint_data():
    try:
        # Authenticate and connect to Google Sheets
        gc = authenticate()
        
        if gc is None:
            st.error("‚ùå Kh√¥ng th·ªÉ x√°c th·ª±c v·ªõi Google Sheets")
            return pd.DataFrame()
        
        # Open the Google Sheet by URL (complaint data)
        sheet_url = "https://docs.google.com/spreadsheets/d/1d6uGPbJV6BsOB6XSB1IS3NhfeaMyMBcaQPvOnNg2yA4/edit"
        sheet_key = sheet_url.split('/d/')[1].split('/')[0]
        
        # Open the spreadsheet and get the worksheet
        try:
            spreadsheet = gc.open_by_key(sheet_key)
            connection_status = st.empty()
            
            # Try to get the "Integrated_Data" worksheet
            try:
                worksheet = spreadsheet.worksheet('Integrated_Data')
            except gspread.exceptions.WorksheetNotFound:
                # Fall back to first worksheet if Integrated_Data doesn't exist
                worksheet = spreadsheet.get_worksheet(0)
            
            # Get all records
            data = worksheet.get_all_records()
            
            # Convert to DataFrame
            df = pd.DataFrame(data)
            
            # Basic data cleaning
            # Convert date columns to datetime if needed
            if "Ng√†y SX" in df.columns:
                try:
                    df["Ng√†y SX"] = pd.to_datetime(df["Ng√†y SX"], format="%d/%m/%Y", errors='coerce')
                    df["Production_Month"] = df["Ng√†y SX"].dt.strftime("%m/%Y")
                    df["Production_Date"] = df["Ng√†y SX"]
                except Exception as e:
                    connection_status.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω c·ªôt ng√†y: {e}")
            
            # Make sure numeric columns are properly typed
            if "SL pack/ c√¢y l·ªói" in df.columns:
                df["SL pack/ c√¢y l·ªói"] = pd.to_numeric(df["SL pack/ c√¢y l·ªói"], errors='coerce').fillna(0)
            
            # Ensure Line column is converted to string for consistent filtering
            if "Line" in df.columns:
                df["Line"] = df["Line"].astype(str)
            
            # Ensure M√°y column is converted to string
            if "M√°y" in df.columns:
                df["M√°y"] = df["M√°y"].astype(str)
            
            # Hide connection status after successful load
            connection_status.empty()
            
            return df
            
        except Exception as e:
            st.error(f"‚ùå L·ªói truy c·∫≠p b·∫£ng d·ªØ li·ªáu khi·∫øu n·∫°i: {str(e)}")
            return pd.DataFrame()
        
    except Exception as e:
        st.error(f"‚ùå L·ªói t·∫£i d·ªØ li·ªáu khi·∫øu n·∫°i: {str(e)}")
        return pd.DataFrame()

# Function to load AQL data
@st.cache_data(ttl=300)  # Cache for 5 minutes
def load_aql_data():
    try:
        # Authenticate and connect to Google Sheets
        gc = authenticate()
        
        if gc is None:
            st.error("‚ùå Kh√¥ng th·ªÉ x√°c th·ª±c v·ªõi Google Sheets")
            return pd.DataFrame()
        
        # Open the Google Sheet by URL (AQL data)
        sheet_url = "https://docs.google.com/spreadsheets/d/1MxvsyZTMMO0L5Cf1FzuXoKD634OClCCefeLjv9B49XU/edit"
        sheet_key = sheet_url.split('/d/')[1].split('/')[0]
        
        # Open the spreadsheet
        try:
            spreadsheet = gc.open_by_key(sheet_key)
            connection_status = st.empty()
            
            # Get the ID AQL worksheet
            try:
                worksheet = spreadsheet.worksheet('ID AQL')
            except gspread.exceptions.WorksheetNotFound:
                connection_status.error(f"‚ùå Kh√¥ng t√¨m th·∫•y b·∫£ng 'ID AQL'")
                return pd.DataFrame()
            
            # Get all records
            data = worksheet.get_all_records()
            
            # Convert to DataFrame
            df = pd.DataFrame(data)
            
            # Basic data cleaning
            # Convert date columns to datetime if needed
            if "Ng√†y SX" in df.columns:
                try:
                    df["Ng√†y SX"] = pd.to_datetime(df["Ng√†y SX"], format="%d/%m/%Y", errors='coerce')
                    df["Production_Month"] = df["Ng√†y SX"].dt.strftime("%m/%Y")
                    df["Production_Date"] = df["Ng√†y SX"]
                except Exception as e:
                    connection_status.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω c·ªôt ng√†y: {e}")
            
            # Make sure numeric columns are properly typed
            if "S·ªë l∆∞·ª£ng hold ( g√≥i/th√πng)" in df.columns:
                df["S·ªë l∆∞·ª£ng hold ( g√≥i/th√πng)"] = pd.to_numeric(df["S·ªë l∆∞·ª£ng hold ( g√≥i/th√πng)"], errors='coerce').fillna(0)
            
            # Ensure Line column is converted to string for consistent filtering
            if "Line" in df.columns:
                df["Line"] = df["Line"].astype(str)
            
            # Hide connection status after successful load
            connection_status.empty()
            
            return df
            
        except Exception as e:
            st.error(f"‚ùå L·ªói truy c·∫≠p b·∫£ng d·ªØ li·ªáu AQL: {str(e)}")
            return pd.DataFrame()
        
    except Exception as e:
        st.error(f"‚ùå L·ªói t·∫£i d·ªØ li·ªáu AQL: {str(e)}")
        return pd.DataFrame()

# Function to load production data (S·∫£n l∆∞·ª£ng)
@st.cache_data(ttl=300)  # Cache for 5 minutes
def load_production_data():
    try:
        # Authenticate and connect to Google Sheets
        gc = authenticate()
        
        if gc is None:
            st.error("‚ùå Kh√¥ng th·ªÉ x√°c th·ª±c v·ªõi Google Sheets")
            return pd.DataFrame()
        
        # Open the Google Sheet by URL (AQL data - same spreadsheet, different worksheet)
        sheet_url = "https://docs.google.com/spreadsheets/d/1MxvsyZTMMO0L5Cf1FzuXoKD634OClCCefeLjv9B49XU/edit"
        sheet_key = sheet_url.split('/d/')[1].split('/')[0]
        
        # Open the spreadsheet
        try:
            spreadsheet = gc.open_by_key(sheet_key)
            connection_status = st.empty()
            
            # Get the S·∫£n l∆∞·ª£ng worksheet
            try:
                worksheet = spreadsheet.worksheet('S·∫£n l∆∞·ª£ng')
            except gspread.exceptions.WorksheetNotFound:
                connection_status.error(f"‚ùå Kh√¥ng t√¨m th·∫•y b·∫£ng 'S·∫£n l∆∞·ª£ng'")
                return pd.DataFrame()
            
            # Get all records
            data = worksheet.get_all_records()
            
            # Convert to DataFrame
            df = pd.DataFrame(data)
            
            # Basic data cleaning
            # Convert date columns to datetime if needed
            if "Ng√†y" in df.columns:
                try:
                    df["Ng√†y"] = pd.to_datetime(df["Ng√†y"], format="%d/%m/%Y", errors='coerce')
                    df["Production_Month"] = df["Ng√†y"].dt.strftime("%m/%Y")
                    df["Production_Date"] = df["Ng√†y"]
                except Exception as e:
                    connection_status.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω c·ªôt ng√†y: {e}")
            
            # Make sure numeric columns are properly typed
            if "S·∫£n l∆∞·ª£ng" in df.columns:
                df["S·∫£n l∆∞·ª£ng"] = pd.to_numeric(df["S·∫£n l∆∞·ª£ng"], errors='coerce').fillna(0)
            
            # Ensure Line column is converted to string for consistent filtering
            if "Line" in df.columns:
                df["Line"] = df["Line"].astype(str)
            
            # Hide connection status after successful load
            connection_status.empty()
            
            return df
            
        except Exception as e:
            st.error(f"‚ùå L·ªói truy c·∫≠p b·∫£ng d·ªØ li·ªáu s·∫£n l∆∞·ª£ng: {str(e)}")
            return pd.DataFrame()
        
    except Exception as e:
        st.error(f"‚ùå L·ªói t·∫£i d·ªØ li·ªáu s·∫£n l∆∞·ª£ng: {str(e)}")
        return pd.DataFrame()

# Function to calculate TEM V√ÄNG
def calculate_tem_vang(aql_df, production_df):
    """Calculate TEM V√ÄNG by combining AQL hold data with production volume data"""
    try:
        # Check if dataframes are empty
        if aql_df.empty or production_df.empty:
            st.error("‚ùå Kh√¥ng th·ªÉ t√≠nh TEM V√ÄNG - thi·∫øu d·ªØ li·ªáu")
            return pd.DataFrame()
        
        # Create copies to avoid modifying originals
        aql_copy = aql_df.copy()
        prod_copy = production_df.copy()
        
        # Group AQL data by date and line to get total hold quantities
        if "Production_Date" in aql_copy.columns and "Line" in aql_copy.columns and "S·ªë l∆∞·ª£ng hold ( g√≥i/th√πng)" in aql_copy.columns:
            aql_grouped = aql_copy.groupby(["Production_Date", "Line"])["S·ªë l∆∞·ª£ng hold ( g√≥i/th√πng)"].sum().reset_index()
            aql_grouped.columns = ["Date", "Line", "Hold_Quantity"]
        else:
            st.warning("‚ö†Ô∏è Thi·∫øu c·ªôt c·∫ßn thi·∫øt trong d·ªØ li·ªáu AQL ƒë·ªÉ t√≠nh TEM V√ÄNG")
            return pd.DataFrame()
        
        # Group production data by date and line to get total production volumes
        if "Production_Date" in prod_copy.columns and "Line" in prod_copy.columns and "S·∫£n l∆∞·ª£ng" in prod_copy.columns:
            prod_grouped = prod_copy.groupby(["Production_Date", "Line"])["S·∫£n l∆∞·ª£ng"].sum().reset_index()
            prod_grouped.columns = ["Date", "Line", "Production_Volume"]
        else:
            st.warning("‚ö†Ô∏è Thi·∫øu c·ªôt c·∫ßn thi·∫øt trong d·ªØ li·ªáu s·∫£n l∆∞·ª£ng ƒë·ªÉ t√≠nh TEM V√ÄNG")
            return pd.DataFrame()
        
        # Merge the grouped data
        tem_vang_df = pd.merge(aql_grouped, prod_grouped, on=["Date", "Line"], how="inner")
        
        # Calculate TEM V√ÄNG percentage
        tem_vang_df["TEM_VANG"] = (tem_vang_df["Hold_Quantity"] / tem_vang_df["Production_Volume"]) * 100
        
        # Add month column for filtering
        tem_vang_df["Production_Month"] = tem_vang_df["Date"].dt.strftime("%m/%Y")
        
        return tem_vang_df
        
    except Exception as e:
        st.error(f"‚ùå L·ªói t√≠nh to√°n TEM V√ÄNG: {str(e)}")
        return pd.DataFrame()

# Function to analyze defect patterns
def analyze_defect_patterns(aql_df):
    """Analyze defect patterns in AQL data"""
    try:
        # Check if dataframe is empty
        if aql_df.empty:
            return {}
        
        # Create copy to avoid modifying original
        df = aql_df.copy()
        
        # Group by defect code to get frequency
        if "Defect code" in df.columns:
            defect_counts = df.groupby("Defect code").size().reset_index(name="Count")
            defect_counts = defect_counts.sort_values("Count", ascending=False)
            
            # Calculate percentages
            total_defects = defect_counts["Count"].sum()
            defect_counts["Percentage"] = (defect_counts["Count"] / total_defects * 100).round(1)
            defect_counts["Cumulative"] = defect_counts["Percentage"].cumsum()
            
            # Identify top defects (80% by Pareto principle)
            vital_few = defect_counts[defect_counts["Cumulative"] <= 80]
            
            # Group by Line and Defect code to get line-specific patterns
            line_defects = df.groupby(["Line", "Defect code"]).size().reset_index(name="Count")
            pivot_line_defects = line_defects.pivot(index="Line", columns="Defect code", values="Count").fillna(0)
            
            # Calculate defect rates by MDG (assuming MDG is stored in "M√°y" column)
            if "M√°y" in df.columns:
                mdg_defects = df.groupby(["Line", "M√°y", "Defect code"]).size().reset_index(name="Count")
            else:
                mdg_defects = pd.DataFrame()
            
            # Return the analysis results
            return {
                "defect_counts": defect_counts,
                "vital_few": vital_few,
                "line_defects": line_defects,
                "pivot_line_defects": pivot_line_defects,
                "mdg_defects": mdg_defects
            }
        else:
            st.warning("‚ö†Ô∏è Thi·∫øu c·ªôt 'Defect code' trong d·ªØ li·ªáu AQL ƒë·ªÉ ph√¢n t√≠ch m·∫´u l·ªói")
            return {}
            
    except Exception as e:
        st.error(f"‚ùå L·ªói ph√¢n t√≠ch m·∫´u l·ªói: {str(e)}")
        return {}

# Function to link internal defects with customer complaints
def link_defects_with_complaints(aql_df, complaint_df):
    """Link internal defects (AQL) with customer complaints"""
    try:
        # Check if dataframes are empty
        if aql_df.empty or complaint_df.empty:
            return pd.DataFrame()
        
        # Create copies to avoid modifying originals
        aql_copy = aql_df.copy()
        complaint_copy = complaint_df.copy()
        
        # Standardize date columns for joining
        if "Production_Date" in aql_copy.columns and "Production_Date" in complaint_copy.columns:
            # Group AQL defects by date, line, and defect code
            if "Defect code" in aql_copy.columns and "Line" in aql_copy.columns:
                aql_grouped = aql_copy.groupby(["Production_Date", "Line", "Defect code"]).size().reset_index(name="Defect_Count")
            else:
                st.warning("‚ö†Ô∏è Thi·∫øu c·ªôt c·∫ßn thi·∫øt trong d·ªØ li·ªáu AQL ƒë·ªÉ li√™n k·∫øt")
                return pd.DataFrame()
            
            # Group complaints by date, line, and defect type
            if "T√™n l·ªói" in complaint_copy.columns and "Line" in complaint_copy.columns:
                # Count unique ticket IDs for each group
                if "M√£ ticket" in complaint_copy.columns:
                    complaint_grouped = complaint_copy.groupby(["Production_Date", "Line", "T√™n l·ªói"])["M√£ ticket"].nunique().reset_index(name="Complaint_Count")
                else:
                    complaint_grouped = complaint_copy.groupby(["Production_Date", "Line", "T√™n l·ªói"]).size().reset_index(name="Complaint_Count")
            else:
                st.warning("‚ö†Ô∏è Thi·∫øu c·ªôt c·∫ßn thi·∫øt trong d·ªØ li·ªáu khi·∫øu n·∫°i ƒë·ªÉ li√™n k·∫øt")
                return pd.DataFrame()
            
            # Create mapping between internal defect codes and customer complaint types
            # This mapping should be customized based on your specific defect codes and complaint types
            defect_map = {
                # Example mapping - update with your actual codes
                "NQ-133": "H·ªü n·∫Øp",
                "NQ-124": "R√°ch OPP",
                "HE-022": "M·∫•t date",
                "HE-023": "Thi·∫øu gia v·ªã",
                "NE-023": "H·ªü n·∫Øp",
                "KK-032": "D·ªã v·∫≠t"
            }
            
            # Add mapped complaint type to AQL data
            aql_grouped["Mapped_Complaint_Type"] = aql_grouped["Defect code"].map(defect_map)
            
            # Group AQL data by date, line, and mapped complaint type
            aql_grouped_mapped = aql_grouped.groupby(["Production_Date", "Line", "Mapped_Complaint_Type"])["Defect_Count"].sum().reset_index()
            
            # Rename complaint type column for joining
            complaint_grouped_renamed = complaint_grouped.rename(columns={"T√™n l·ªói": "Mapped_Complaint_Type"})
            
            # Join AQL and complaint data
            # Use a window of +/- 7 days to account for lag between production and complaint
            linked_defects = pd.DataFrame()
            
            for _, aql_row in aql_grouped_mapped.iterrows():
                prod_date = aql_row["Production_Date"]
                line = aql_row["Line"]
                complaint_type = aql_row["Mapped_Complaint_Type"]
                
                # Skip if complaint type mapping is null
                if pd.isna(complaint_type):
                    continue
                
                # Find complaints within the window
                date_min = prod_date - timedelta(days=1)  # 1 day before production
                date_max = prod_date + timedelta(days=14)  # Up to 14 days after production
                
                matching_complaints = complaint_grouped_renamed[
                    (complaint_grouped_renamed["Production_Date"] >= date_min) &
                    (complaint_grouped_renamed["Production_Date"] <= date_max) &
                    (complaint_grouped_renamed["Line"] == line) &
                    (complaint_grouped_renamed["Mapped_Complaint_Type"] == complaint_type)
                ]
                
                if not matching_complaints.empty:
                    total_complaints = matching_complaints["Complaint_Count"].sum()
                    
                    linked_row = pd.DataFrame({
                        "Production_Date": [prod_date],
                        "Line": [line],
                        "Defect_Type": [complaint_type],
                        "Internal_Defect_Count": [aql_row["Defect_Count"]],
                        "Customer_Complaint_Count": [total_complaints],
                        "Defect_to_Complaint_Ratio": [aql_row["Defect_Count"] / total_complaints if total_complaints > 0 else float('inf')]
                    })
                    
                    linked_defects = pd.concat([linked_defects, linked_row], ignore_index=True)
            
            return linked_defects
            
        else:
            st.warning("‚ö†Ô∏è Thi·∫øu c·ªôt ng√†y ƒë·ªÉ li√™n k·∫øt l·ªói v·ªõi khi·∫øu n·∫°i")
            return pd.DataFrame()
            
    except Exception as e:
        st.error(f"‚ùå L·ªói li√™n k·∫øt l·ªói v·ªõi khi·∫øu n·∫°i: {str(e)}")
        return pd.DataFrame()

# Load the data
@st.cache_data(ttl=600)  # Cache the combined data for 10 minutes
def load_all_data():
    """Load and prepare all required data"""
    
    # Load raw data
    complaint_df = load_complaint_data()
    aql_df = load_aql_data()
    production_df = load_production_data()
    
    # Calculate TEM V√ÄNG
    tem_vang_df = calculate_tem_vang(aql_df, production_df)
    
    # Analyze defect patterns
    defect_patterns = analyze_defect_patterns(aql_df)
    
    # Link defects with complaints
    linked_defects_df = link_defects_with_complaints(aql_df, complaint_df)
    
    return {
        "complaint_data": complaint_df,
        "aql_data": aql_df,
        "production_data": production_df,
        "tem_vang_data": tem_vang_df,
        "defect_patterns": defect_patterns,
        "linked_defects": linked_defects_df
    }

# Title and description
st.markdown('<div class="main-header">B√°o c√°o ch·∫•t l∆∞·ª£ng CF MMB</div>', unsafe_allow_html=True)

# Load all data
data = load_all_data()

# Check if key dataframes are empty
if data["aql_data"].empty or data["production_data"].empty:
    st.warning("‚ö†Ô∏è Thi·∫øu d·ªØ li·ªáu c·∫ßn thi·∫øt. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi Google Sheet.")
    # Still continue rendering with available data

# Create a sidebar for filters
with st.sidebar:
    st.markdown("<h2 style='text-align: center; color: #1E3A8A;'>B·ªô l·ªçc</h2>", unsafe_allow_html=True)
    
    # Initialize filtered dataframes
    filtered_aql_df = data["aql_data"].copy()
    filtered_complaint_df = data["complaint_data"].copy()
    filtered_tem_vang_df = data["tem_vang_data"].copy()
    
    # Date filter for production data
    st.subheader("Kho·∫£ng th·ªùi gian s·∫£n xu·∫•t")
    
    # Get min and max dates from AQL data
    if not data["aql_data"].empty and "Production_Date" in data["aql_data"].columns:
        min_prod_date = data["aql_data"]["Production_Date"].min().date()
        max_prod_date = data["aql_data"]["Production_Date"].max().date()
    else:
        min_prod_date = datetime.now().date() - timedelta(days=365)
        max_prod_date = datetime.now().date()
    
    # Create date range selector for production data
    prod_date_range = st.date_input(
        "Ch·ªçn kho·∫£ng th·ªùi gian s·∫£n xu·∫•t",
        value=(min_prod_date, max_prod_date),
        min_value=min_prod_date - timedelta(days=365),
        max_value=max_prod_date + timedelta(days=30)
    )
    
    # Apply production date filter if a range is selected
    if len(prod_date_range) == 2:
        start_date, end_date = prod_date_range
        
        # Convert to datetime for filtering
        start_datetime = pd.Timestamp(start_date)
        end_datetime = pd.Timestamp(end_date) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
        
        # Apply to AQL data
        if "Production_Date" in filtered_aql_df.columns:
            filtered_aql_df = filtered_aql_df[
                (filtered_aql_df["Production_Date"] >= start_datetime) & 
                (filtered_aql_df["Production_Date"] <= end_datetime)
            ]
        
        # Apply to TEM V√ÄNG data
        if not filtered_tem_vang_df.empty and "Date" in filtered_tem_vang_df.columns:
            filtered_tem_vang_df = filtered_tem_vang_df[
                (filtered_tem_vang_df["Date"] >= start_datetime) & 
                (filtered_tem_vang_df["Date"] <= end_datetime)
            ]
    
    # Date filter for complaint data
    st.subheader("Kho·∫£ng th·ªùi gian khi·∫øu n·∫°i")
    
    # Get min and max dates from complaint data
    if not data["complaint_data"].empty and "Production_Date" in data["complaint_data"].columns:
        min_complaint_date = data["complaint_data"]["Production_Date"].min().date()
        max_complaint_date = data["complaint_data"]["Production_Date"].max().date()
    else:
        min_complaint_date = datetime.now().date() - timedelta(days=365)
        max_complaint_date = datetime.now().date()
    
    # Create date range selector for complaint data
    complaint_date_range = st.date_input(
        "Ch·ªçn kho·∫£ng th·ªùi gian khi·∫øu n·∫°i",
        value=(min_complaint_date, max_complaint_date),
        min_value=min_complaint_date - timedelta(days=365),
        max_value=max_complaint_date + timedelta(days=30)
    )
    
    # Apply complaint date filter if a range is selected
    if len(complaint_date_range) == 2:
        start_date, end_date = complaint_date_range
        
        # Convert to datetime for filtering
        start_datetime = pd.Timestamp(start_date)
        end_datetime = pd.Timestamp(end_date) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
        
        # Apply to complaint data
        if "Production_Date" in filtered_complaint_df.columns:
            filtered_complaint_df = filtered_complaint_df[
                (filtered_complaint_df["Production_Date"] >= start_datetime) & 
                (filtered_complaint_df["Production_Date"] <= end_datetime)
            ]
    
    # Line filter - Always include all lines from 1 to 8 regardless of data
    all_lines = ["T·∫•t c·∫£"] + [str(i) for i in range(1, 9)]
    selected_line = st.selectbox("üè≠ Ch·ªçn Line s·∫£n xu·∫•t", all_lines)
    
    if selected_line != "T·∫•t c·∫£":
        # Apply filter to dataframes if the line exists in them
        if not filtered_tem_vang_df.empty and "Line" in filtered_tem_vang_df.columns:
            filtered_tem_vang_df = filtered_tem_vang_df[filtered_tem_vang_df["Line"] == selected_line]
        
        if "Line" in filtered_aql_df.columns:
            filtered_aql_df = filtered_aql_df[filtered_aql_df["Line"] == selected_line]
        
        if "Line" in filtered_complaint_df.columns:
            filtered_complaint_df = filtered_complaint_df[filtered_complaint_df["Line"] == selected_line]
    
    # Product filter
    if not data["complaint_data"].empty and "T√™n s·∫£n ph·∫©m" in data["complaint_data"].columns:
        try:
            products = ["T·∫•t c·∫£"] + sorted(data["complaint_data"]["T√™n s·∫£n ph·∫©m"].unique().tolist())
            selected_product = st.selectbox("üçú Ch·ªçn s·∫£n ph·∫©m", products)
            
            if selected_product != "T·∫•t c·∫£":
                filtered_complaint_df = filtered_complaint_df[filtered_complaint_df["T√™n s·∫£n ph·∫©m"] == selected_product]
                
                # Filter AQL data by item if possible
                if "T√™n s·∫£n ph·∫©m" in filtered_aql_df.columns:
                    filtered_aql_df = filtered_aql_df[filtered_aql_df["T√™n s·∫£n ph·∫©m"] == selected_product]
        except Exception as e:
            st.warning(f"L·ªói ·ªü b·ªô l·ªçc s·∫£n ph·∫©m: {e}")
    
    # Refresh button
    if st.button("üîÑ L√†m m·ªõi d·ªØ li·ªáu", use_container_width=True):
        st.cache_data.clear()
        st.experimental_rerun()
    
    # Show last update time
    st.markdown(f"**C·∫≠p nh·∫≠t cu·ªëi:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    
    # Add auto-refresh checkbox
    auto_refresh = st.checkbox("‚è±Ô∏è T·ª± ƒë·ªông l√†m m·ªõi (5p)", value=False)

# Main dashboard layout with tabs for the 3 pages
tab1, tab2, tab3 = st.tabs([
    "üìà Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng s·∫£n xu·∫•t", 
    "üîç Ph√¢n t√≠ch khi·∫øu n·∫°i kh√°ch h√†ng",
    "üîÑ Li√™n k·∫øt ch·∫•t l∆∞·ª£ng trong v√† ngo√†i"
])

# Page 1: Production Quality Analysis (TEM V√ÄNG and defects by line/MDG)
with tab1:
    st.markdown('<div class="sub-header">T·ªïng quan ch·∫•t l∆∞·ª£ng s·∫£n xu·∫•t</div>', unsafe_allow_html=True)
    
    # Key metrics row
    metrics_col1, metrics_col2, metrics_col3, metrics_col4 = st.columns(4)
    
    with metrics_col1:
        if not filtered_tem_vang_df.empty:
            avg_tem_vang = filtered_tem_vang_df["TEM_VANG"].mean()
            tem_target = 2.18  # TEM V√ÄNG target
            tem_delta = avg_tem_vang - tem_target
            
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-title">TEM V√ÄNG trung b√¨nh</div>
                <div class="metric-value">{avg_tem_vang:.2f}%</div>
                <div style="color: {'red' if tem_delta > 0 else 'green'};">
                    {f"{tem_delta:.2f}% {'cao h∆°n' if tem_delta > 0 else 'th·∫•p h∆°n'} m·ª•c ti√™u"}
                </div>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-title">TEM V√ÄNG trung b√¨nh</div>
                <div class="metric-value">N/A</div>
            </div>
            """, unsafe_allow_html=True)
    
    with metrics_col2:
        if not filtered_tem_vang_df.empty:
            total_hold = filtered_tem_vang_df["Hold_Quantity"].sum()
            
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-title">T·ªïng s·ªë l∆∞·ª£ng hold</div>
                <div class="metric-value">{total_hold:,.0f}</div>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-title">T·ªïng s·ªë l∆∞·ª£ng hold</div>
                <div class="metric-value">N/A</div>
            </div>
            """, unsafe_allow_html=True)
    
    with metrics_col3:
        if not filtered_aql_df.empty and "Defect code" in filtered_aql_df.columns:
            defect_types = filtered_aql_df["Defect code"].nunique()
            
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-title">S·ªë lo·∫°i l·ªói</div>
                <div class="metric-value">{defect_types}</div>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-title">S·ªë lo·∫°i l·ªói</div>
                <div class="metric-value">N/A</div>
            </div>
            """, unsafe_allow_html=True)
            
    with metrics_col4:
        if not filtered_tem_vang_df.empty:
            total_production = filtered_tem_vang_df["Production_Volume"].sum()
            
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-title">T·ªïng s·∫£n l∆∞·ª£ng</div>
                <div class="metric-value">{total_production:,.0f}</div>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-title">T·ªïng s·∫£n l∆∞·ª£ng</div>
                <div class="metric-value">N/A</div>
            </div>
            """, unsafe_allow_html=True)
    
    # TEM V√ÄNG Analysis
    st.markdown('<div class="sub-header">Ph√¢n t√≠ch TEM V√ÄNG</div>', unsafe_allow_html=True)
    
    tem_col1, tem_col2 = st.columns(2)
    
    with tem_col1:
        # TEM V√ÄNG trend over time
        if not filtered_tem_vang_df.empty:
            try:
                # Group by date to get daily average TEM V√ÄNG
                daily_tem_vang = filtered_tem_vang_df.groupby("Date")[["TEM_VANG", "Hold_Quantity"]].mean().reset_index()
                
                # Sort by date
                daily_tem_vang = daily_tem_vang.sort_values("Date")
                
                # Create figure
                fig = go.Figure()
                
                # Add TEM V√ÄNG line
                fig.add_trace(go.Scatter(
                    x=daily_tem_vang["Date"],
                    y=daily_tem_vang["TEM_VANG"],
                    mode="lines+markers",
                    name="TEM V√ÄNG",
                    line=dict(color="royalblue", width=2),
                    marker=dict(size=6)
                ))
                
                # Add target line
                fig.add_hline(
                    y=2.18,
                    line_dash="dash",
                    line_color="red",
                    annotation_text="M·ª•c ti√™u (2.18%)"
                )
                
                # Update layout
                fig.update_layout(
                    title="Xu h∆∞·ªõng TEM V√ÄNG theo th·ªùi gian",
                    xaxis_title="Ng√†y",
                    yaxis_title="TEM V√ÄNG (%)",
                    height=350,
                    margin=dict(l=40, r=40, t=40, b=40)
                )
                
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì xu h∆∞·ªõng TEM V√ÄNG: {str(e)}")
    
    with tem_col2:
        # TEM V√ÄNG by line
        if not filtered_tem_vang_df.empty:
            try:
                # Group by line to get average TEM V√ÄNG per line
                line_tem_vang = filtered_tem_vang_df.groupby("Line")[["TEM_VANG", "Hold_Quantity"]].mean().reset_index()
                
                # Sort by TEM V√ÄNG value
                line_tem_vang = line_tem_vang.sort_values("TEM_VANG", ascending=False)
                
                # Create figure
                fig = go.Figure()
                
                # Add TEM V√ÄNG bars
                fig.add_trace(go.Bar(
                    x=line_tem_vang["Line"],
                    y=line_tem_vang["TEM_VANG"],
                    name="TEM V√ÄNG",
                    marker_color="royalblue",
                    text=line_tem_vang["TEM_VANG"].round(2).astype(str) + "%",
                    textposition="auto"
                ))
                
                # Add target line
                fig.add_hline(
                    y=2.18,
                    line_dash="dash",
                    line_color="red",
                    annotation_text="M·ª•c ti√™u (2.18%)"
                )
                
                # Update layout
                fig.update_layout(
                    title="TEM V√ÄNG theo Line s·∫£n xu·∫•t",
                    xaxis_title="Line",
                    yaxis_title="TEM V√ÄNG (%)",
                    height=350,
                    margin=dict(l=40, r=40, t=40, b=40)
                )
                
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì TEM V√ÄNG theo line: {str(e)}")
    
    # Defect Analysis by Line and MDG
    st.markdown('<div class="sub-header">Ph√¢n t√≠ch l·ªói theo Line v√† MDG</div>', unsafe_allow_html=True)
    
    defect_col1, defect_col2 = st.columns(2)
    
    with defect_col1:
        # Pareto chart of defects
        if "defect_patterns" in data and "defect_counts" in data["defect_patterns"]:
            try:
                defect_counts = data["defect_patterns"]["defect_counts"]
                
                # Create Pareto chart
                fig = make_subplots(specs=[[{"secondary_y": True}]])
                
                # Add bars for defect counts
                fig.add_trace(
                    go.Bar(
                        x=defect_counts["Defect code"],
                        y=defect_counts["Count"],
                        name="S·ªë l·ªói",
                        marker_color="steelblue"
                    ),
                    secondary_y=False
                )
                
                # Add line for cumulative percentage
                fig.add_trace(
                    go.Scatter(
                        x=defect_counts["Defect code"],
                        y=defect_counts["Cumulative"],
                        name="T√≠ch l≈©y %",
                        mode="lines+markers",
                        marker=dict(color="firebrick"),
                        line=dict(color="firebrick", width=2)
                    ),
                    secondary_y=True
                )
                
                # Add 80% reference line
                fig.add_hline(
                    y=80,
                    line_dash="dash",
                    line_color="green",
                    annotation_text="80% l·ªói",
                    secondary_y=True
                )
                
                # Update layout
                fig.update_layout(
                    title="Ph√¢n t√≠ch Pareto c√°c lo·∫°i l·ªói",
                    xaxis_title="M√£ l·ªói",
                    height=350,
                    margin=dict(l=40, r=40, t=40, b=40)
                )
                
                # Set y-axes titles
                fig.update_yaxes(title_text="S·ªë l·ªói", secondary_y=False)
                fig.update_yaxes(title_text="T√≠ch l≈©y %", secondary_y=True)
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Add Pareto analysis insight
                if "vital_few" in data["defect_patterns"]:
                    vital_few = data["defect_patterns"]["vital_few"]
                    
                    st.markdown(f"""
                    <div class="insight-card">
                        <div class="insight-title">Ph√¢n t√≠ch Pareto</div>
                        <div class="insight-content">
                            <p>{len(vital_few)} lo·∫°i l·ªói ({len(vital_few)/len(defect_counts)*100:.0f}% t·ªïng s·ªë lo·∫°i) chi·∫øm 80% s·ªë l·ªói.</p>
                            <p>T·∫≠p trung c·∫£i ti·∫øn ch·∫•t l∆∞·ª£ng v√†o: {', '.join(vital_few['Defect code'].tolist())}</p>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
            except Exception as e:
                st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì Pareto: {str(e)}")
    
    with defect_col2:
        # Defects by line heatmap
        if "defect_patterns" in data and "pivot_line_defects" in data["defect_patterns"]:
            try:
                pivot_df = data["defect_patterns"]["pivot_line_defects"]
                
                if not pivot_df.empty:
                    # Create heatmap
                    fig = px.imshow(
                        pivot_df,
                        labels=dict(x="M√£ l·ªói", y="Line", color="S·ªë l·ªói"),
                        x=pivot_df.columns,
                        y=pivot_df.index,
                        color_continuous_scale="YlOrRd",
                        aspect="auto"
                    )
                    
                    # Update layout
                    fig.update_layout(
                        title="Ph√¢n b·ªë l·ªói theo Line",
                        height=350,
                        margin=dict(l=40, r=40, t=40, b=40)
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu l·ªói ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì nhi·ªát")
            except Exception as e:
                st.error(f"L·ªói t·∫°o b·∫£n ƒë·ªì nhi·ªát l·ªói: {str(e)}")
    
    # MDG Analysis
    st.markdown('<div class="sub-header">Ph√¢n t√≠ch theo MDG (M√°y)</div>', unsafe_allow_html=True)
    
    if "defect_patterns" in data and "mdg_defects" in data["defect_patterns"] and not data["defect_patterns"]["mdg_defects"].empty:
        try:
            mdg_defects = data["defect_patterns"]["mdg_defects"].copy()
            
            # Group by Line and MDG to get total defects
            line_mdg_summary = mdg_defects.groupby(["Line", "M√°y"])["Count"].sum().reset_index()
            
            # Create bar chart
            fig = px.bar(
                line_mdg_summary,
                x="M√°y",
                y="Count",
                color="Line",
                title="Ph√¢n t√≠ch l·ªói theo MDG v√† Line",
                labels={"M√°y": "MDG (M√°y)", "Count": "S·ªë l·ªói"},
                barmode="group"
            )
            
            # Update layout
            fig.update_layout(
                height=400,
                margin=dict(l=40, r=40, t=40, b=40)
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Display top MDG-defect combinations
            st.markdown("#### Nh·ªØng t·ªï h·ª£p MDG-Lo·∫°i l·ªói ph·ªï bi·∫øn nh·∫•t")
            
            # Group by Line, MDG, and Defect code
            top_mdg_defects = mdg_defects.sort_values("Count", ascending=False).head(10)
            
            # Create a styled dataframe
            st.dataframe(top_mdg_defects, use_container_width=True, height=250)
            
        except Exception as e:
            st.error(f"L·ªói trong ph√¢n t√≠ch MDG: {str(e)}")
    else:
        st.warning("‚ö†Ô∏è D·ªØ li·ªáu ph√¢n t√≠ch MDG kh√¥ng c√≥ s·∫µn")

# Page 2: Customer Complaint Analysis
with tab2:
    st.markdown('<div class="sub-header">T·ªïng quan khi·∫øu n·∫°i kh√°ch h√†ng</div>', unsafe_allow_html=True)
    
    # Check if complaint dataframe is empty
    if filtered_complaint_df.empty:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu khi·∫øu n·∫°i ƒë·ªÉ ph√¢n t√≠ch")
    else:
        # Key metrics row
        comp_col1, comp_col2, comp_col3, comp_col4 = st.columns(4)
        
        with comp_col1:
            if "M√£ ticket" in filtered_complaint_df.columns:
                total_complaints = filtered_complaint_df["M√£ ticket"].nunique()
                st.markdown(f"""
                <div class="metric-card">
                    <div class="metric-title">T·ªïng s·ªë khi·∫øu n·∫°i</div>
                    <div class="metric-value">{total_complaints}</div>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.warning("Thi·∫øu c·ªôt 'M√£ ticket'")
        
        with comp_col2:
            if "SL pack/ c√¢y l·ªói" in filtered_complaint_df.columns:
                total_defective_packs = filtered_complaint_df["SL pack/ c√¢y l·ªói"].sum()
                st.markdown(f"""
                <div class="metric-card">
                    <div class="metric-title">S·ªë l∆∞·ª£ng g√≥i l·ªói</div>
                    <div class="metric-value">{total_defective_packs:,.0f}</div>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.warning("Thi·∫øu c·ªôt 'SL pack/ c√¢y l·ªói'")
        
        with comp_col3:
            if "T·ªânh" in filtered_complaint_df.columns:
                total_provinces = filtered_complaint_df["T·ªânh"].nunique()
                st.markdown(f"""
                <div class="metric-card">
                    <div class="metric-title">S·ªë t·ªânh/th√†nh b·ªã ·∫£nh h∆∞·ªüng</div>
                    <div class="metric-value">{total_provinces}</div>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.warning("Thi·∫øu c·ªôt 'T·ªânh'")
        
        with comp_col4:
            if "T√™n l·ªói" in filtered_complaint_df.columns:
                total_defect_types = filtered_complaint_df["T√™n l·ªói"].nunique()
                st.markdown(f"""
                <div class="metric-card">
                    <div class="metric-title">S·ªë lo·∫°i l·ªói ƒë∆∞·ª£c b√°o c√°o</div>
                    <div class="metric-value">{total_defect_types}</div>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.warning("Thi·∫øu c·ªôt 'T√™n l·ªói'")
        
        # Complaint Analysis
        st.markdown('<div class="sub-header">Ph√¢n t√≠ch khi·∫øu n·∫°i</div>', unsafe_allow_html=True)
        
        comp_col1, comp_col2 = st.columns(2)
        
        with comp_col1:
            if "T√™n s·∫£n ph·∫©m" in filtered_complaint_df.columns and "M√£ ticket" in filtered_complaint_df.columns:
                try:
                    # Group by product
                    product_complaints = filtered_complaint_df.groupby("T√™n s·∫£n ph·∫©m").agg({
                        "M√£ ticket": "nunique",
                        "SL pack/ c√¢y l·ªói": "sum"
                    }).reset_index()
                    
                    # Sort by complaint count
                    product_complaints = product_complaints.sort_values("M√£ ticket", ascending=False).head(10)
                    
                    # Create horizontal bar chart with improved styling
                    fig = go.Figure()
                    
                    # Add bars for complaints
                    fig.add_trace(go.Bar(
                        y=product_complaints["T√™n s·∫£n ph·∫©m"],
                        x=product_complaints["M√£ ticket"],
                        name="S·ªë khi·∫øu n·∫°i",
                        orientation='h',
                        marker=dict(
                            color=product_complaints["M√£ ticket"],
                            colorscale='Reds',
                            line=dict(width=1, color='black')
                        ),
                        text=product_complaints["M√£ ticket"],
                        textposition="outside",
                        textfont=dict(size=12)
                    ))
                    
                    # Update layout with better styling
                    fig.update_layout(
                        title={
                            'text': "Top 10 s·∫£n ph·∫©m c√≥ nhi·ªÅu khi·∫øu n·∫°i nh·∫•t",
                            'y':0.9,
                            'x':0.5,
                            'xanchor': 'center',
                            'yanchor': 'top'
                        },
                        xaxis_title="S·ªë l∆∞·ª£ng khi·∫øu n·∫°i",
                        yaxis_title="S·∫£n ph·∫©m",
                        height=400,
                        margin=dict(l=20, r=20, t=60, b=40),
                        plot_bgcolor='rgba(240,240,240,0.5)',
                        xaxis=dict(
                            showgrid=True,
                            gridcolor='rgba(200,200,200,0.5)'
                        ),
                        yaxis=dict(
                            showgrid=True,
                            gridcolor='rgba(200,200,200,0.5)'
                        )
                    )
                    
                    # Add value labels on the bars
                    for i in range(len(product_complaints)):
                        fig.add_annotation(
                            x=product_complaints["M√£ ticket"].iloc[i] + 1,
                            y=i,
                            text=str(product_complaints["M√£ ticket"].iloc[i]),
                            showarrow=False,
                            font=dict(color="black", size=12)
                        )
                    
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì khi·∫øu n·∫°i theo s·∫£n ph·∫©m: {str(e)}")
            else:
                st.warning("Thi·∫øu c·ªôt c·∫ßn thi·∫øt cho bi·ªÉu ƒë·ªì s·∫£n ph·∫©m")
        
        with comp_col2:
            if "T√™n l·ªói" in filtered_complaint_df.columns and "M√£ ticket" in filtered_complaint_df.columns:
                try:
                    # Group by defect type
                    defect_complaints = filtered_complaint_df.groupby("T√™n l·ªói").agg({
                        "M√£ ticket": "nunique",
                        "SL pack/ c√¢y l·ªói": "sum"
                    }).reset_index()
                    
                    # Calculate percentages
                    defect_complaints["Complaint %"] = (defect_complaints["M√£ ticket"] / defect_complaints["M√£ ticket"].sum() * 100).round(1)
                    
                    # Create improved pie chart
                    fig = go.Figure()
                    
                    # Add pie chart with improved styling
                    fig.add_trace(go.Pie(
                        labels=defect_complaints["T√™n l·ªói"],
                        values=defect_complaints["M√£ ticket"],
                        hole=0.4,
                        textinfo="percent",
                        hoverinfo="label+value+percent",
                        textfont=dict(size=12),
                        marker=dict(
                            colors=px.colors.qualitative.Set3,
                            line=dict(color='white', width=2)
                        ),
                        pull=[0.05 if i == defect_complaints["M√£ ticket"].idxmax() else 0 for i in range(len(defect_complaints))]
                    ))
                    
                    # Add a custom annotation in the center
                    fig.add_annotation(
                        text=f"T·ªïng s·ªë<br>{defect_complaints['M√£ ticket'].sum():,.0f}",
                        font=dict(size=14, color="#1E3A8A", family="Arial", weight="bold"),
                        showarrow=False,
                        x=0.5,
                        y=0.5
                    )
                    
                    # Update layout with better styling
                    fig.update_layout(
                        title={
                            'text': "Ph√¢n t√≠ch khi·∫øu n·∫°i theo lo·∫°i l·ªói",
                            'y':0.9,
                            'x':0.5,
                            'xanchor': 'center',
                            'yanchor': 'top'
                        },
                        height=400,
                        margin=dict(l=20, r=20, t=60, b=40),
                        legend=dict(
                            orientation="v",
                            yanchor="middle",
                            y=0.5,
                            xanchor="left",
                            x=1.05,
                            font=dict(size=10)
                        )
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì khi·∫øu n·∫°i theo lo·∫°i l·ªói: {str(e)}")
            else:
                st.warning("Thi·∫øu c·ªôt c·∫ßn thi·∫øt cho bi·ªÉu ƒë·ªì lo·∫°i l·ªói")
        
        # Complaint Timeline and Production Analysis
        st.markdown('<div class="sub-header">Ph√¢n t√≠ch xu h∆∞·ªõng khi·∫øu n·∫°i theo th·ªùi gian</div>', unsafe_allow_html=True)
        
        time_col1, time_col2 = st.columns(2)
        
        with time_col1:
            if "Production_Date" in filtered_complaint_df.columns and "M√£ ticket" in filtered_complaint_df.columns:
                try:
                    # Group by date
                    date_complaints = filtered_complaint_df.groupby("Production_Date").agg({
                        "M√£ ticket": "nunique",
                        "SL pack/ c√¢y l·ªói": "sum"
                    }).reset_index()
                    
                    # Sort by date
                    date_complaints = date_complaints.sort_values("Production_Date")
                    
                    # Create figure - Changed to column chart instead of line chart
                    fig = go.Figure()
                    
                    # Add bars for complaints
                    fig.add_trace(go.Bar(
                        x=date_complaints["Production_Date"],
                        y=date_complaints["M√£ ticket"],
                        name="S·ªë khi·∫øu n·∫°i",
                        marker_color='rgba(70, 130, 180, 0.8)',
                        text=date_complaints["M√£ ticket"],
                        textposition="outside"
                    ))
                    
                    # Update layout with better styling
                    fig.update_layout(
                        title={
                            'text': "Xu h∆∞·ªõng khi·∫øu n·∫°i theo th·ªùi gian",
                            'y':0.9,
                            'x':0.5,
                            'xanchor': 'center',
                            'yanchor': 'top'
                        },
                        xaxis_title="Ng√†y s·∫£n xu·∫•t",
                        yaxis_title="S·ªë l∆∞·ª£ng khi·∫øu n·∫°i",
                        height=400,
                        margin=dict(l=20, r=20, t=60, b=40),
                        plot_bgcolor='rgba(240,240,240,0.5)',
                        xaxis=dict(
                            showgrid=True,
                            gridcolor='rgba(200,200,200,0.5)'
                        ),
                        yaxis=dict(
                            showgrid=True,
                            gridcolor='rgba(200,200,200,0.5)'
                        )
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì xu h∆∞·ªõng khi·∫øu n·∫°i: {str(e)}")
            else:
                st.warning("Thi·∫øu c·ªôt ng√†y cho bi·ªÉu ƒë·ªì xu h∆∞·ªõng")
        
        with time_col2:
            if "Line" in filtered_complaint_df.columns and "M√£ ticket" in filtered_complaint_df.columns:
                try:
                    # Group by line
                    line_complaints = filtered_complaint_df.groupby("Line").agg({
                        "M√£ ticket": "nunique",
                        "SL pack/ c√¢y l·ªói": "sum"
                    }).reset_index()
                    
                    # Sort by line number
                    line_complaints = line_complaints.sort_values("Line")
                    
                    # Create figure
                    fig = go.Figure()
                    
                    # Add bars for complaints with adjusted scale for 8 lines
                    fig.add_trace(go.Bar(
                        x=line_complaints["Line"],
                        y=line_complaints["M√£ ticket"],
                        name="S·ªë khi·∫øu n·∫°i",
                        marker_color='rgba(128, 0, 0, 0.8)',
                        text=line_complaints["M√£ ticket"],
                        textposition="outside"
                    ))
                    
                    # Update layout with better styling and fixed scale for 8 lines
                    fig.update_layout(
                        title={
                            'text': "Khi·∫øu n·∫°i theo Line s·∫£n xu·∫•t",
                            'y':0.9,
                            'x':0.5,
                            'xanchor': 'center',
                            'yanchor': 'top'
                        },
                        xaxis_title="Line s·∫£n xu·∫•t",
                        yaxis_title="S·ªë l∆∞·ª£ng khi·∫øu n·∫°i",
                        height=400,
                        margin=dict(l=20, r=20, t=60, b=40),
                        plot_bgcolor='rgba(240,240,240,0.5)',
                        xaxis=dict(
                            showgrid=True,
                            gridcolor='rgba(200,200,200,0.5)',
                            categoryorder='array',
                            categoryarray=['1', '2', '3', '4', '5', '6', '7', '8']
                        ),
                        yaxis=dict(
                            showgrid=True,
                            gridcolor='rgba(200,200,200,0.5)',
                            range=[0, 8]  # Fixed scale from 0 to 8
                        )
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì khi·∫øu n·∫°i theo line: {str(e)}")
            else:
                st.warning("Thi·∫øu c·ªôt Line cho bi·ªÉu ƒë·ªì line")
        
        # Geographic Distribution of Complaints
        st.markdown('<div class="sub-header">Ph√¢n b·ªë ƒë·ªãa l√Ω c·ªßa khi·∫øu n·∫°i</div>', unsafe_allow_html=True)
        
        if "T·ªânh" in filtered_complaint_df.columns and "M√£ ticket" in filtered_complaint_df.columns:
            try:
                # Group by province
                province_complaints = filtered_complaint_df.groupby("T·ªânh").agg({
                    "M√£ ticket": "nunique",
                    "SL pack/ c√¢y l·ªói": "sum"
                }).reset_index()
                
                # Sort by complaint count
                province_complaints = province_complaints.sort_values("M√£ ticket", ascending=False)
                
                # Create figure
                fig = px.bar(
                    province_complaints.head(15),  # Top 15 provinces
                    x="T·ªânh",
                    y="M√£ ticket",
                    color="SL pack/ c√¢y l·ªói",
                    title="Top c√°c t·ªânh/th√†nh theo s·ªë l∆∞·ª£ng khi·∫øu n·∫°i",
                    labels={"T·ªânh": "T·ªânh/Th√†nh", "M√£ ticket": "S·ªë l∆∞·ª£ng khi·∫øu n·∫°i", "SL pack/ c√¢y l·ªói": "S·ªë g√≥i l·ªói"},
                    color_continuous_scale="Viridis"
                )
                
                # Update layout
                fig.update_layout(
                    height=400,
                    margin=dict(l=40, r=40, t=40, b=100),
                    xaxis_tickangle=-45
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Calculate percentages for top provinces
                top_provinces = province_complaints.head(5)
                total_complaints = province_complaints["M√£ ticket"].sum()
                top_provinces["Percentage"] = (top_provinces["M√£ ticket"] / total_complaints * 100).round(1)
                
                # Display insight
                st.markdown(f"""
                <div class="insight-card">
                    <div class="insight-title">Ph√¢n t√≠ch ƒë·ªãa l√Ω</div>
                    <div class="insight-content">
                        <p>Top 5 t·ªânh/th√†nh chi·∫øm {top_provinces['Percentage'].sum():.1f}% t·ªïng s·ªë khi·∫øu n·∫°i.</p>
                        <p>T·ªânh/th√†nh cao nh·∫•t ({top_provinces.iloc[0]['T·ªânh']}) chi·∫øm {top_provinces.iloc[0]['Percentage']:.1f}% t·ªïng s·ªë khi·∫øu n·∫°i.</p>
                        <p>C√¢n nh·∫Øc ch∆∞∆°ng tr√¨nh c·∫£i ti·∫øn ch·∫•t l∆∞·ª£ng t·∫°i c√°c khu v·ª±c n√†y.</p>
                    </div>
                </div>
                """, unsafe_allow_html=True)
            except Exception as e:
                st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì ph√¢n b·ªë ƒë·ªãa l√Ω: {str(e)}")
        else:
            st.warning("Thi·∫øu c·ªôt t·ªânh/th√†nh ƒë·ªÉ ph√¢n t√≠ch ƒë·ªãa l√Ω")
        
        # Personnel Analysis
        st.markdown('<div class="sub-header">Ph√¢n t√≠ch nh√¢n s·ª± s·∫£n xu·∫•t</div>', unsafe_allow_html=True)
        
        personnel_col1, personnel_col2 = st.columns(2)
        
        with personnel_col1:
            if "QA" in filtered_complaint_df.columns and "M√£ ticket" in filtered_complaint_df.columns:
                try:
                    # Group by QA
                    qa_complaints = filtered_complaint_df.groupby("QA").agg({
                        "M√£ ticket": "nunique",
                        "SL pack/ c√¢y l·ªói": "sum"
                    }).reset_index()
                    
                    # Remove NaN values
                    qa_complaints = qa_complaints.dropna(subset=["QA"])
                    
                    # Sort by complaint count
                    qa_complaints = qa_complaints.sort_values("M√£ ticket", ascending=False)
                    
                    # Create figure
                    fig = go.Figure()
                    
                    # Add bars for complaints
                    fig.add_trace(go.Bar(
                        x=qa_complaints["QA"],
                        y=qa_complaints["M√£ ticket"],
                        name="S·ªë khi·∫øu n·∫°i",
                        marker_color="purple",
                        text=qa_complaints["M√£ ticket"],
                        textposition="outside"
                    ))
                    
                    # Update layout
                    fig.update_layout(
                        title="Khi·∫øu n·∫°i theo nh√¢n vi√™n QA",
                        xaxis_title="Nh√¢n vi√™n QA",
                        yaxis_title="S·ªë l∆∞·ª£ng khi·∫øu n·∫°i",
                        height=400,
                        margin=dict(l=40, r=40, t=40, b=80),
                        xaxis_tickangle=-45
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì khi·∫øu n·∫°i theo QA: {str(e)}")
            else:
                st.warning("Thi·∫øu c·ªôt QA cho ph√¢n t√≠ch nh√¢n s·ª±")
        
        with personnel_col2:
            if "T√™n Tr∆∞·ªüng ca" in filtered_complaint_df.columns and "M√£ ticket" in filtered_complaint_df.columns:
                try:
                    # Group by shift leader
                    leader_complaints = filtered_complaint_df.groupby("T√™n Tr∆∞·ªüng ca").agg({
                        "M√£ ticket": "nunique",
                        "SL pack/ c√¢y l·ªói": "sum"
                    }).reset_index()
                    
                    # Remove NaN values
                    leader_complaints = leader_complaints.dropna(subset=["T√™n Tr∆∞·ªüng ca"])
                    
                    # Sort by complaint count
                    leader_complaints = leader_complaints.sort_values("M√£ ticket", ascending=False)
                    
                    # Create figure
                    fig = go.Figure()
                    
                    # Add bars for complaints
                    fig.add_trace(go.Bar(
                        x=leader_complaints["T√™n Tr∆∞·ªüng ca"],
                        y=leader_complaints["M√£ ticket"],
                        name="S·ªë khi·∫øu n·∫°i",
                        marker_color="darkred",
                        text=leader_complaints["M√£ ticket"],
                        textposition="outside"
                    ))
                    
                    # Update layout
                    fig.update_layout(
                        title="Khi·∫øu n·∫°i theo Tr∆∞·ªüng ca",
                        xaxis_title="Tr∆∞·ªüng ca",
                        yaxis_title="S·ªë l∆∞·ª£ng khi·∫øu n·∫°i",
                        height=400,
                        margin=dict(l=40, r=40, t=40, b=80),
                        xaxis_tickangle=-45
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì khi·∫øu n·∫°i theo tr∆∞·ªüng ca: {str(e)}")
            else:
                st.warning("Thi·∫øu c·ªôt tr∆∞·ªüng ca cho ph√¢n t√≠ch nh√¢n s·ª±")
        
        # Complaint Details Table
        st.markdown('<div class="sub-header">Chi ti·∫øt khi·∫øu n·∫°i</div>', unsafe_allow_html=True)
        
        try:
            # Create a display dataframe with key columns
            if not filtered_complaint_df.empty:
                display_cols = [
                    "M√£ ticket", "Ng√†y ti·∫øp nh·∫≠n", "T·ªânh", "Ng√†y SX", "T√™n s·∫£n ph·∫©m",
                    "SL pack/ c√¢y l·ªói", "T√™n l·ªói", "Line", "QA", "T√™n Tr∆∞·ªüng ca"
                ]
                
                # Only include columns that exist in the dataframe
                display_cols = [col for col in display_cols if col in filtered_complaint_df.columns]
                
                # Create display dataframe
                display_df = filtered_complaint_df[display_cols].copy()
                
                # Sort by most recent complaints first
                if "Ng√†y ti·∫øp nh·∫≠n" in display_df.columns:
                    display_df = display_df.sort_values("Ng√†y ti·∫øp nh·∫≠n", ascending=False)
                
                # Format dates for display
                for date_col in ["Ng√†y ti·∫øp nh·∫≠n", "Ng√†y SX"]:
                    if date_col in display_df.columns and pd.api.types.is_datetime64_any_dtype(display_df[date_col]):
                        display_df[date_col] = display_df[date_col].dt.strftime("%d/%m/%Y")
                
                # Display the table
                st.dataframe(display_df, use_container_width=True, height=400)
            else:
                st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu khi·∫øu n·∫°i ƒë·ªÉ hi·ªÉn th·ªã")
        except Exception as e:
            st.error(f"L·ªói hi·ªÉn th·ªã chi ti·∫øt khi·∫øu n·∫°i: {str(e)}")

# Page 3: Linking Internal and External Quality
with tab3:
    st.markdown('<div class="sub-header">Ph√¢n t√≠ch li√™n k·∫øt ch·∫•t l∆∞·ª£ng trong v√† ngo√†i</div>', unsafe_allow_html=True)
    
    # Check if linked defects data is available
    if "linked_defects" in data and not data["linked_defects"].empty:
        # Key metrics row
        link_col1, link_col2, link_col3, link_col4 = st.columns(4)
        
        linked_df = data["linked_defects"].copy()
        
        with link_col1:
            total_linkages = len(linked_df)
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-title">T·ªïng s·ªë li√™n k·∫øt</div>
                <div class="metric-value">{total_linkages}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with link_col2:
            avg_ratio = linked_df["Defect_to_Complaint_Ratio"].replace([float('inf'), -float('inf')], np.nan).mean()
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-title">T·ª∑ l·ªá trung b√¨nh L·ªói:Khi·∫øu n·∫°i</div>
                <div class="metric-value">{avg_ratio:.1f}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with link_col3:
            unique_defect_types = linked_df["Defect_Type"].nunique()
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-title">S·ªë lo·∫°i l·ªói li√™n k·∫øt</div>
                <div class="metric-value">{unique_defect_types}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with link_col4:
            total_lines = linked_df["Line"].nunique()
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-title">S·ªë Line b·ªã ·∫£nh h∆∞·ªüng</div>
                <div class="metric-value">{total_lines}</div>
            </div>
            """, unsafe_allow_html=True)
        
        # Defect to Complaint Ratio Analysis
        st.markdown('<div class="sub-header">Ph√¢n t√≠ch t·ª∑ l·ªá L·ªói-Khi·∫øu n·∫°i</div>', unsafe_allow_html=True)
        
        ratio_col1, ratio_col2 = st.columns(2)
        
        with ratio_col1:
            try:
                # Group by defect type
                defect_type_ratios = linked_df.groupby("Defect_Type").agg({
                    "Internal_Defect_Count": "sum",
                    "Customer_Complaint_Count": "sum"
                }).reset_index()
                
                # Calculate overall ratio
                defect_type_ratios["Ratio"] = defect_type_ratios["Internal_Defect_Count"] / defect_type_ratios["Customer_Complaint_Count"]
                
                # Sort by ratio
                defect_type_ratios = defect_type_ratios.sort_values("Ratio")
                
                # Create figure
                fig = go.Figure()
                
                # Add bars for ratio
                fig.add_trace(go.Bar(
                    y=defect_type_ratios["Defect_Type"],
                    x=defect_type_ratios["Ratio"],
                    orientation="h",
                    marker_color="teal",
                    text=defect_type_ratios["Ratio"].round(1),
                    textposition="outside"
                ))
                
                # Update layout
                fig.update_layout(
                    title="T·ª∑ l·ªá L·ªói-Khi·∫øu n·∫°i theo lo·∫°i l·ªói",
                    xaxis_title="T·ª∑ l·ªá (L·ªói n·ªôi b·ªô : Khi·∫øu n·∫°i kh√°ch h√†ng)",
                    yaxis_title="Lo·∫°i l·ªói",
                    height=400,
                    margin=dict(l=40, r=40, t=40, b=40)
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Add interpretation
                st.markdown(f"""
                <div class="insight-card">
                    <div class="insight-title">Di·ªÖn gi·∫£i t·ª∑ l·ªá</div>
                    <div class="insight-content">
                        <p>T·ª∑ l·ªá cao h∆°n cho th·∫•y nhi·ªÅu l·ªói n·ªôi b·ªô ƒë∆∞·ª£c ph√°t hi·ªán cho m·ªói khi·∫øu n·∫°i kh√°ch h√†ng.</p>
                        <p>T·ª∑ l·ªá th·∫•p h∆°n cho th·∫•y l·ªói kh√¥ng ƒë∆∞·ª£c ph√°t hi·ªán hi·ªáu qu·∫£ trong qu√° tr√¨nh s·∫£n xu·∫•t.</p>
                        <p><strong>{defect_type_ratios.iloc[-1]['Defect_Type']}</strong> c√≥ t·ª∑ l·ªá cao nh·∫•t ({defect_type_ratios.iloc[-1]['Ratio']:.1f}), cho th·∫•y ph√°t hi·ªán n·ªôi b·ªô hi·ªáu qu·∫£.</p>
                        <p><strong>{defect_type_ratios.iloc[0]['Defect_Type']}</strong> c√≥ t·ª∑ l·ªá th·∫•p nh·∫•t ({defect_type_ratios.iloc[0]['Ratio']:.1f}), c·∫ßn c·∫£i thi·ªán ph√°t hi·ªán l·ªói.</p>
                    </div>
                </div>
                """, unsafe_allow_html=True)
            except Exception as e:
                st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì ph√¢n t√≠ch t·ª∑ l·ªá: {str(e)}")
        
        with ratio_col2:
            try:
                # Group by line
                line_ratios = linked_df.groupby("Line").agg({
                    "Internal_Defect_Count": "sum",
                    "Customer_Complaint_Count": "sum"
                }).reset_index()
                
                # Calculate overall ratio
                line_ratios["Ratio"] = line_ratios["Internal_Defect_Count"] / line_ratios["Customer_Complaint_Count"]
                
                # Create scatter plot
                fig = px.scatter(
                    line_ratios,
                    x="Internal_Defect_Count",
                    y="Customer_Complaint_Count",
                    size="Ratio",
                    color="Line",
                    hover_name="Line",
                    text="Line",
                    title="L·ªói n·ªôi b·ªô v√† khi·∫øu n·∫°i kh√°ch h√†ng theo Line"
                )
                
                # Update markers
                fig.update_traces(
                    marker=dict(sizemode="area", sizeref=0.1),
                    textposition="top center"
                )
                
                # Add diagonal reference line (1:1 ratio)
                max_val = max(line_ratios["Internal_Defect_Count"].max(), line_ratios["Customer_Complaint_Count"].max())
                fig.add_trace(go.Scatter(
                    x=[0, max_val],
                    y=[0, max_val],
                    mode="lines",
                    line=dict(color="gray", dash="dash"),
                    name="T·ª∑ l·ªá 1:1"
                ))
                
                # Update layout
                fig.update_layout(
                    xaxis_title="S·ªë l·ªói n·ªôi b·ªô",
                    yaxis_title="S·ªë khi·∫øu n·∫°i kh√°ch h√†ng",
                    height=400,
                    margin=dict(l=40, r=40, t=40, b=40)
                )
                
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì t·ª∑ l·ªá theo line: {str(e)}")
        
                # Timeline Analysis
        st.markdown('<div class="sub-header">Ph√¢n t√≠ch theo th·ªùi gian</div>', unsafe_allow_html=True)
        
        try:
            # Group by date
            date_analysis = linked_df.groupby("Production_Date").agg({
                "Internal_Defect_Count": "sum",
                "Customer_Complaint_Count": "sum"
            }).reset_index()
            
            # Calculate ratio
            date_analysis["Ratio"] = (
                date_analysis["Internal_Defect_Count"]
                / date_analysis["Customer_Complaint_Count"]
            )
            
            # Sort by date
            date_analysis = date_analysis.sort_values("Production_Date")
            
            # Create figure with secondary y-axis
            fig = make_subplots(specs=[[{"secondary_y": True}]])
            
            # Add lines for internal defects and customer complaints
            fig.add_trace(
                go.Scatter(
                    x=date_analysis["Production_Date"],
                    y=date_analysis["Internal_Defect_Count"],
                    name="L·ªói n·ªôi b·ªô",
                    mode="lines+markers",
                    line=dict(color="royalblue", width=2)
                ),
                secondary_y=False
            )
            fig.add_trace(
                go.Scatter(
                    x=date_analysis["Production_Date"],
                    y=date_analysis["Customer_Complaint_Count"],
                    name="Khi·∫øu n·∫°i kh√°ch h√†ng",
                    mode="lines+markers",
                    line=dict(color="firebrick", width=2)
                ),
                secondary_y=False
            )
            # Add ratio line
            fig.add_trace(
                go.Scatter(
                    x=date_analysis["Production_Date"],
                    y=date_analysis["Ratio"],
                    name="T·ª∑ l·ªá L·ªói:Khi·∫øu n·∫°i",
                    mode="lines",
                    line=dict(color="green", width=2, dash="dash")
                ),
                secondary_y=True
            )
            
            # Update layout
            fig.update_layout(
                title="L·ªói n·ªôi b·ªô v√† khi·∫øu n·∫°i kh√°ch h√†ng theo th·ªùi gian",
                xaxis_title="Ng√†y s·∫£n xu·∫•t",
                height=400,
                margin=dict(l=40, r=40, t=40, b=40),
                legend=dict(orientation="h", yanchor="bottom", y=1.02)
            )
            fig.update_yaxes(title_text="S·ªë l∆∞·ª£ng", secondary_y=False)
            fig.update_yaxes(title_text="T·ª∑ l·ªá L·ªói:Khi·∫øu n·∫°i", secondary_y=True)
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Calculate correlation and display insight
            correlation = date_analysis["Internal_Defect_Count"].corr(
                date_analysis["Customer_Complaint_Count"]
            )
            st.markdown(f"""
            <div class="insight-card">
                <div class="insight-title">Ph√¢n t√≠ch t∆∞∆°ng quan</div>
                <div class="insight-content">
                    <p>T∆∞∆°ng quan gi·ªØa l·ªói n·ªôi b·ªô v√† khi·∫øu n·∫°i kh√°ch h√†ng l√† <strong>{correlation:.2f}</strong>.</p>
                    <p>{'T∆∞∆°ng quan d∆∞∆°ng n√†y cho th·∫•y s·ª± gia tƒÉng l·ªói n·ªôi b·ªô c√≥ li√™n quan ƒë·∫øn s·ª± gia tƒÉng khi·∫øu n·∫°i kh√°ch h√†ng, v·ªõi ƒë·ªô tr·ªÖ t·ª´ v√†i ng√†y ƒë·∫øn v√†i tu·∫ßn.' if correlation > 0 else 'T∆∞∆°ng quan n√†y cho th·∫•y l·ªói n·ªôi b·ªô v√† khi·∫øu n·∫°i kh√°ch h√†ng c√≥ th·ªÉ kh√¥ng li√™n quan tr·ª±c ti·∫øp ho·∫∑c c√≥ ƒë·ªô tr·ªÖ ƒë√°ng k·ªÉ gi·ªØa v·∫•n ƒë·ªÅ s·∫£n xu·∫•t v√† ph·∫£n h·ªìi c·ªßa kh√°ch h√†ng.'}</p>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
        except Exception as e:
            st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì ph√¢n t√≠ch th·ªùi gian: {str(e)}")
        
        
        # Detection Effectiveness Analysis
        st.markdown('<div class="sub-header">Ph√¢n t√≠ch hi·ªáu qu·∫£ ph√°t hi·ªán l·ªói</div>', unsafe_allow_html=True)
        
        try:
            # Calculate detection effectiveness for each defect type
            effectiveness_df = linked_df.groupby("Defect_Type").agg({
                "Internal_Defect_Count": "sum",
                "Customer_Complaint_Count": "sum"
            }).reset_index()
            
            # Calculate effectiveness percentage
            effectiveness_df["Total_Issues"] = (
                effectiveness_df["Internal_Defect_Count"]
                + effectiveness_df["Customer_Complaint_Count"]
            )
            effectiveness_df["Detection_Effectiveness"] = (
                effectiveness_df["Internal_Defect_Count"]
                / effectiveness_df["Total_Issues"]
                * 100
            ).round(1)
            
            # Sort by effectiveness
            effectiveness_df = effectiveness_df.sort_values("Detection_Effectiveness")
            
            # Create figure
            fig = go.Figure()
            fig.add_trace(go.Bar(
                y=effectiveness_df["Defect_Type"],
                x=effectiveness_df["Detection_Effectiveness"],
                orientation="h",
                marker_color=effectiveness_df["Detection_Effectiveness"].map(
                    lambda x: "green" if x >= 90 else ("orange" if x >= 75 else "red")
                ),
                text=effectiveness_df["Detection_Effectiveness"].astype(str) + "%",
                textposition="outside"
            ))
            fig.add_vline(x=75, line_dash="dash", line_color="orange", annotation_text="75% (Ch·∫•p nh·∫≠n ƒë∆∞·ª£c)")
            fig.add_vline(x=90, line_dash="dash", line_color="green", annotation_text="90% (Xu·∫•t s·∫Øc)")
            fig.update_layout(
                title="Hi·ªáu qu·∫£ ph√°t hi·ªán l·ªói n·ªôi b·ªô theo lo·∫°i l·ªói",
                xaxis_title="Hi·ªáu qu·∫£ ph√°t hi·ªán (%)",
                yaxis_title="Lo·∫°i l·ªói",
                height=400,
                margin=dict(l=40, r=40, t=40, b=40),
                xaxis=dict(range=[0, 100])
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Identify poor detection areas
            poor_detection = effectiveness_df[
                effectiveness_df["Detection_Effectiveness"] < 75
            ]
            if not poor_detection.empty:
                low_items = "".join([
                    f"<li><strong>{row['Defect_Type']}</strong>: {row['Detection_Effectiveness']}% hi·ªáu qu·∫£</li>"
                    for _, row in poor_detection.iterrows()
                ])
                st.markdown(f"""
                <div class="warning-card">
                    <div class="warning-title">Khu v·ª±c ph√°t hi·ªán l·ªói k√©m</div>
                    <div class="insight-content">
                        <p>C√°c lo·∫°i l·ªói sau ƒë√¢y c√≥ hi·ªáu qu·∫£ ph√°t hi·ªán d∆∞·ªõi 75%, cho th·∫•y c∆° h·ªôi c·∫£i ti·∫øn ƒë√°ng k·ªÉ:</p>
                        <ul>
                            {low_items}
                        </ul>
                        <p>C√¢n nh·∫Øc tri·ªÉn khai c√°c c·∫£i ti·∫øn nh·∫Øm m·ª•c ti√™u trong ph∆∞∆°ng ph√°p ph√°t hi·ªán cho c√°c lo·∫°i l·ªói n√†y.</p>
                    </div>
                </div>
                """, unsafe_allow_html=True)
            
        except Exception as e:
            st.error(f"L·ªói t·∫°o ph√¢n t√≠ch hi·ªáu qu·∫£ ph√°t hi·ªán: {str(e)}")
        else:
            st.warning("""
            ‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu l·ªói li√™n k·∫øt. ƒêi·ªÅu n√†y c√≥ th·ªÉ do:
            
            1. Kh√¥ng ƒë·ªß d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·ªÉ thi·∫øt l·∫≠p k·∫øt n·ªëi
            2. Kh√¥ng kh·ªõp m√£ l·ªói gi·ªØa d·ªØ li·ªáu n·ªôi b·ªô v√† d·ªØ li·ªáu kh√°ch h√†ng
            3. V·∫•n ƒë·ªÅ t√≠ch h·ª£p d·ªØ li·ªáu
            
            Vui l√≤ng ƒë·∫£m b·∫£o c·∫£ d·ªØ li·ªáu AQL v√† khi·∫øu n·∫°i ƒë·ªÅu c√≥ s·∫µn v√† ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng ƒë√∫ng.
            """)

